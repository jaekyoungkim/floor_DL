{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "밑바닥부터시작하는딥러닝2 -(ch1-4).ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMba8aEPVUVyGeQrysJERn2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaekyoungkim/floor_DL/blob/main/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%EB%94%A5%EB%9F%AC%EB%8B%9D2_(ch1_4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-p2YLaIYgO4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0263516-003b-484f-f108-1bb7af78bfa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch-2'...\n",
            "remote: Enumerating objects: 606, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 606 (delta 1), reused 5 (delta 0), pack-reused 598\u001b[K\n",
            "Receiving objects: 100% (606/606), 29.82 MiB | 25.40 MiB/s, done.\n",
            "Resolving deltas: 100% (361/361), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch-2.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch1. 신경망 복습 "
      ],
      "metadata": {
        "id": "9p28Nwy8gS6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x=np.array([1,2,3])\n",
        "x.__class__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FJMVl0AgU0f",
        "outputId": "80293d16-fb2c-438d-fa6d-1ab3c6b36408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSZRQQOxgehr",
        "outputId": "6c18d76e-1589-4b83-8c05-c000265909d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQv9i0QhggWj",
        "outputId": "3b4590a4-ce2b-4314-ec11-c1d25de65411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W= np.array([[1,2,3],[4,5,6]])"
      ],
      "metadata": {
        "id": "ENtvW7krgg0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz_UOx_ugmVc",
        "outputId": "4aa5bcaf-b630-4dd2-bc5b-28202349371f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T_fMyXlgnWv",
        "outputId": "26935316-a495-4ca6-b2c7-712c2a00370d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([1,2,3])\n",
        "b=np.array([4,5,6])\n",
        "np.dot(a,b) # 벡터의 내적"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83abMEM-gn6-",
        "outputId": "d02f1d36-4a06-4120-e314-2d8fc93455a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A=np.array([[1,2],[3,4]])\n",
        "B=np.array([4,5,6])"
      ],
      "metadata": {
        "id": "UyBP-9vqg08T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot(A,B) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_n3FXLbg5e5",
        "outputId": "b6027fd6-2b3d-4a4d-d1df-97e88a1be4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19, 22],\n",
              "       [43, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A=np.array([[1,2],[3,4]])\n",
        "B=np.array([[5,6],[7,8]])"
      ],
      "metadata": {
        "id": "6Q-Cs2XSg8ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(A,B)  # 행렬곱"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YsGqRfChETM",
        "outputId": "3069e483-b0e7-4024-81bf-526443b32cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19, 22],\n",
              "       [43, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 100 NUMPY EXCERSICE 예제 해보기, 좋은 샘플임"
      ],
      "metadata": {
        "id": "P4v9nHMyhFes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경명에서 수행하는 작업 : 학습과 추론\n",
        "# 입력층, 출력층, 은닉층으로 구성됨\n",
        "# 가중치, 편향을 통해 계산됨\n"
      ],
      "metadata": {
        "id": "OgvHrleLhYiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# h(1x4) = x(1x2)W(2x4) + b(1x4)\n",
        "# h1 = x1 * w11 + x2w21 + b1\n",
        "# x : 입력\n",
        "# h: 은닉층 뉴런\n",
        "# W : 가중치\n",
        "# b: 편향"
      ],
      "metadata": {
        "id": "phvb-51Y3VeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "W1  = np.random.randn(2,4) ; W1 # 2x4 # "
      ],
      "metadata": {
        "id": "6tZv_vmr30sX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a306cf05-e674-4587-9dd6-5d4326b441ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.21648767, -0.48698938, -0.55972081, -0.33360003],\n",
              "       [-0.07943261,  0.33523018,  1.91602756,  0.49719856]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b1 = np.random.randn(4); b1 # 편향 "
      ],
      "metadata": {
        "id": "e6aGiZ9o3mUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a99f587a-770d-4f09-d5c2-c984faa7c303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.09281632, -1.32468704,  0.1211265 ,  1.45028844])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.randn(10,2) ;x  # 10개의 샘플 데이터 10x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkSttPPMNPjj",
        "outputId": "9d420973-fd08-4356-fc85-c3b4f5606b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.79263062, -0.75536546],\n",
              "       [-0.96074454, -0.7729176 ],\n",
              "       [ 0.27417157,  1.24564265],\n",
              "       [-0.17863988, -0.25924527],\n",
              "       [-1.5889804 ,  0.12993258],\n",
              "       [ 0.79132852, -0.05668989],\n",
              "       [ 2.02010822,  0.22829108],\n",
              "       [ 1.57134666, -0.50833922],\n",
              "       [ 0.31941044, -0.37383323],\n",
              "       [ 1.06823862,  0.33171146]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = np.matmul(x, W1)+b1 ; h # b1은 브로드캐스트됨, (4,) -> (10,4)로 복제됨\n",
        "# 은닉층의 뉴런은 4개"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIATYmBaNR5z",
        "outputId": "9db0e29a-02be-42bf-ac3c-b804f977189d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.8114084 , -1.19190565, -0.88252269,  1.33914341],\n",
              "       [-1.01452271, -1.11591996, -0.8220562 ,  1.38649933],\n",
              "       [ 0.327398  , -1.04062868,  2.3543526 ,  1.97815653],\n",
              "       [-0.10390437, -1.32459816, -0.27560613,  1.38098633],\n",
              "       [-1.85047963, -0.50731314,  1.2594663 ,  2.04497463],\n",
              "       [ 1.05996073, -1.72905979, -0.43041594,  1.15811509],\n",
              "       [ 2.5321193 , -2.23192823, -0.57215811,  0.88988629],\n",
              "       [ 2.04471886, -2.26032683, -1.73238088,  0.67334163],\n",
              "       [ 0.51106973, -1.60555672, -0.77392894,  1.15786377],\n",
              "       [ 1.36596671, -1.73370821,  0.1587794 ,  1.25885047]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1+np.exp(-x))"
      ],
      "metadata": {
        "id": "P7axyvAdNjS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=sigmoid(h);a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhWjMziwN2pD",
        "outputId": "e1879bec-e2e5-4057-9ee0-ee41eb0edc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.30759045, 0.23291829, 0.29265529, 0.79234904],\n",
              "       [0.26609568, 0.24676887, 0.30532736, 0.80003279],\n",
              "       [0.58112614, 0.26102871, 0.91327957, 0.87848451],\n",
              "       [0.47404725, 0.2100543 , 0.43153132, 0.79914936],\n",
              "       [0.13581659, 0.3758236 , 0.77893422, 0.88543885],\n",
              "       [0.74268304, 0.15070788, 0.39402701, 0.76099005],\n",
              "       [0.92636305, 0.09691974, 0.360739  , 0.70886671],\n",
              "       [0.8854129 , 0.09446241, 0.15028329, 0.662251  ],\n",
              "       [0.62505721, 0.16720642, 0.31562981, 0.76094433],\n",
              "       [0.79672773, 0.15011387, 0.53961167, 0.77882816]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = np.random.randn(4,3); W2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw8iW2SINU2b",
        "outputId": "e01b0cb5-2afb-43e4-a7b7-405d6351d932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.37739058, -1.37091245,  1.02414928],\n",
              "       [ 0.53476128, -0.57238529, -1.18448979],\n",
              "       [ 0.78459979, -1.51697355, -0.88192149],\n",
              "       [ 0.2837107 ,  0.82732871, -0.72231865]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b2 = np.random.randn(3) ; b1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_s59bX2OTB8",
        "outputId": "7f24367d-fb22-4d99-878e-812733989fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.08098443, -0.3624163 , -1.45582362])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = np.matmul(a, W2) + b2;s # 10x3 3차원 데이터로 변환되었다는 의미 / 3개의 분류를 할 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cd9kkMBOUOX",
        "outputId": "23ded0fb-a3de-49f8-fc36-e2f1aeda7ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.37118812, -0.25582204,  0.46471824],\n",
              "       [ 0.44787185, -0.21973042,  0.38908963],\n",
              "       [ 0.52083425, -1.51711378,  0.10200395],\n",
              "       [ 0.24057675, -0.67597789,  0.53488725],\n",
              "       [ 1.09215297, -0.76278842, -0.37657407],\n",
              "       [-0.2014279 , -0.98496228,  0.94094466],\n",
              "       [-0.52409655, -1.19861005,  1.25977899],\n",
              "       [-0.64735516, -0.86037521,  1.44002741],\n",
              "       [-0.09211181, -0.71426242,  0.8701091 ],\n",
              "       [-0.15689965, -1.2648029 ,  0.85571906]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 완전연결계층에 의한 변환은 기하학에서의 아핀변환에 해당(Affine)\n",
        "# 계층은 파이썬 클래스로 구현하며, 기본변환을 수행하는 메서드의 이름은 forward()\n",
        "# 모든 계층은 forward() / backward()를 가짐\n",
        "# 모든계층은 인스턴스 변수인 params / Grads를 가짐\n",
        "# params : 가중치와 편향같은 매개변수를 담은 리스트\n",
        "# grads : params에 저장된 각 매개변수에 대응하여 해당 매개변수의 기울기를 보관하는 리스트\n"
      ],
      "metadata": {
        "id": "iePQD3KWOeCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class Sigmoid:\n",
        "  def __init__(self): \n",
        "    self.params = []\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return 1/ (1+np.exp(-x))\n",
        "# 주변환처리는 forward(x) 메서드가 담당함\n"
      ],
      "metadata": {
        "id": "vHtrwZYtQjuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine:\n",
        "  def __init__(self, W,b):\n",
        "    self.params = [W,b]\n",
        "  \n",
        "  def forward(self,x):\n",
        "    W, b = self.params \n",
        "    out = np.matmul(x,W) + b\n",
        "    return out\n",
        "   # 초기화할때 가중치와 편향을 받음\n",
        "   #  "
      ],
      "metadata": {
        "id": "II82XECdQzyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x-affine-sigmoid-affine-s 구현해보기\n",
        "\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    I,H,O = input_size, hidden_size, output_size\n",
        "    #가중치편향초기화\n",
        "    W1 = np.random.randn(I, H)\n",
        "    b1 = np.random.randn(H)\n",
        "    W2 = np.random.randn(H,O)\n",
        "    b2 = np.random.randn(O)\n",
        "\n",
        "    #계층생성 / 3개의 계층을 생성함\n",
        "    self.layers = [Affine(W1,b1), Sigmoid(), Affine(W2,b2)]\n",
        "\n",
        "    # 모든 가중치를 리스트에 모은다\n",
        "    self.params = []\n",
        "    for layer in self.layers: \n",
        "      self.params += layer.params\n",
        "  \n",
        "  def predict(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer.forward(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "helnhOirRFYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = ['A', 'B']\n",
        "a+= ['C','D']\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6C84UEER4LI",
        "outputId": "7bd00f3d-a220-4e5c-b13d-d09397f95dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'B', 'C', 'D']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.randn(10,2)\n",
        "model = TwoLayerNet(2,4,3)\n",
        "s=model.predict(x)"
      ],
      "metadata": {
        "id": "GVbFuRe1SiY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb2FV0qMSveD",
        "outputId": "154e137f-7719-49c8-da8f-bb5a35a97748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.50968998, -3.69145486, -0.59078053],\n",
              "       [-1.6117588 , -4.22416638, -0.71167142],\n",
              "       [-0.49862053, -2.90384628, -1.64117301],\n",
              "       [-0.73843196, -2.6384056 , -0.9049674 ],\n",
              "       [-0.96349443, -2.85194653, -0.70539678],\n",
              "       [-0.42929553, -2.41121233, -1.55367667],\n",
              "       [-1.5465118 , -3.96349097, -0.71224558],\n",
              "       [-0.90985446, -3.14941086, -1.01884055],\n",
              "       [-0.82460339, -2.64136731, -0.77112327],\n",
              "       [-0.98907426, -3.44949816, -1.19451352]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습되지 않은 신경망은 좋은추론을 해낼수없음\n",
        "#학습을 먼저 수행하고, 그 학습된 매개변수를 이용해 추론을 수행하는 흐름이 일반적\n"
      ],
      "metadata": {
        "id": "OihKEYbISsGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수 :학습이 얼마나 잘 되고 있는지를 알기 위한 척도, 신경망의 성능을 나타내는 척도로 손실을 사용\n",
        "# 예측한 결과를 비교하여 예측이 얼마나 나쁜가를 산출한 단일값(스칼라)\n",
        "# 교차엔트로피 오차(cross entropy error) : 예측한 확률과 정답레이블을 이요해 계산\n",
        "#"
      ],
      "metadata": {
        "id": "vFeG2sa0aPpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x-affine-sigmoid-affine-softmax-crossentropy-error-L 과정구현\n",
        "# 소프트 맥스의 출력값은 0~1실수\n"
      ],
      "metadata": {
        "id": "IdCLu6GCaoBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기울기 개념의 등장 : 수학에서 말하는 기울기와는 다름, 수학에서의 기울기는 벡터에 대한 미분으로 한정, 한편 딥러닝에서는 행렬이나 텐서에 대해서도 미분을 정의함\n",
        "# 국소적인 미분을 구할수있다면 전체의 미분을 구할수있게하는 아이디어 : 연쇄법칙\n"
      ],
      "metadata": {
        "id": "RDpEemVSvgkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 역전파 종류-\n",
        "# 덧셈노드\n",
        "# 곱셈노드\n",
        "# 분기노드\n",
        "# REPEAT노드(N개의 분기노드)\n",
        "# SUM노드\n",
        "# MATMUL노드"
      ],
      "metadata": {
        "id": "EOL3IT7CSitg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "D, N = 8,7\n",
        "x = np.random.randn(1,D);x # 8 개랜덤값"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42xbZ2TKRBsu",
        "outputId": "caf37aa8-7224-45c1-bd43-6b889d35e0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.5794089 , -0.4090421 ,  0.11616307, -0.80426539,  0.86277395,\n",
              "        -0.22785349,  1.2346049 ,  0.36791626]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.repeat(x,N, axis=0); y # x를 N번 반복"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8M4znzyxCzF",
        "outputId": "919ecb33-0765-49ab-f6d9-7303b7235e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.5794089 , -0.4090421 ,  0.11616307, -0.80426539,  0.86277395,\n",
              "        -0.22785349,  1.2346049 ,  0.36791626],\n",
              "       [-0.5794089 , -0.4090421 ,  0.11616307, -0.80426539,  0.86277395,\n",
              "        -0.22785349,  1.2346049 ,  0.36791626],\n",
              "       [-0.5794089 , -0.4090421 ,  0.11616307, -0.80426539,  0.86277395,\n",
              "        -0.22785349,  1.2346049 ,  0.36791626],\n",
              "       [-0.5794089 , -0.4090421 ,  0.11616307, -0.80426539,  0.86277395,\n",
              "        -0.22785349,  1.2346049 ,  0.36791626],\n",
              "       [-0.5794089 , -0.4090421 ,  0.11616307, -0.80426539,  0.86277395,\n",
              "        -0.22785349,  1.2346049 ,  0.36791626],\n",
              "       [-0.5794089 , -0.4090421 ,  0.11616307, -0.80426539,  0.86277395,\n",
              "        -0.22785349,  1.2346049 ,  0.36791626],\n",
              "       [-0.5794089 , -0.4090421 ,  0.11616307, -0.80426539,  0.86277395,\n",
              "        -0.22785349,  1.2346049 ,  0.36791626]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dx = np.random.randn(N,D) ;dx.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR9alEL6QvnM",
        "outputId": "06ec67bc-c13d-46ea-8115-4452314cb05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dy = np.sum(dx, axis=0, keepdims=True);dy #  keepdims=True : 2차원을 유지시킴\n",
        "# (1,D) 출력 NOT (D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-GuZAhuOXIL",
        "outputId": "02546eca-1c9a-4aa2-94aa-f4379035e333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.75530335,  2.4007671 ,  0.80061987,  3.1102779 ,  0.78699361,\n",
              "         0.44033144,  1.3401611 , -2.93366021]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dy.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfl4VmG3xixg",
        "outputId": "d415d1b4-342c-499f-8c10-8e34103946dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SUM노드의 역전파\n",
        "D,N = 8,7 \n",
        "x=np.random.randn(N,D)\n",
        "y=np.sum(x, axis=0, keepdims=True) \n",
        "dx = np.random.randn(1,D)\n",
        "dy = np.repeat(dy, N, axis=0)"
      ],
      "metadata": {
        "id": "Fmp8KVWxxWXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# matmul노드의 역전파\n",
        "# y = xW\n",
        "# (1,H) = (1,D) * (D,H) \n",
        "# (N,H) = (N,D) * (D,H) / 미니배치 처리인 경우\n",
        "\n"
      ],
      "metadata": {
        "id": "rDottCRByvAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatMul:\n",
        "  def __init__(self, W):\n",
        "    self.params = [W]\n",
        "    self.grads = [np.zeros_like(W)]\n",
        "    self.x = None  \n",
        "  \n",
        "  def forward(self, x): \n",
        "    W, = self.params  \n",
        "    out = np.matmul(x, W)\n",
        "    self.x = x\n",
        "    return out \n",
        "  \n",
        "  def  backward(self, dout ):\n",
        "    W, = self.params \n",
        "    dx = np.matmul(dout, W.T) \n",
        "    dy = np.matmul(self.x.T, dout )\n",
        "    self.grads[0][...] = dW  # 기울기값 설정하는 부분, 생략기호 ... 사용. 넘파이 배열이 가리키는 메모리 위치를 고정시킨 다음, 그 위치에 원소들을 덮어씀\n",
        "    # 생략기호는 넘파이 배열의 덮어쓰기를 수행\n",
        "    # grads[0] =dw처럼 그냥 할당하면 얕은 복사가 이루어지고 grads[0][...]= dw처럼 덮어쓰면 깊은 복사가 이뤄짐\n",
        "    return dx "
      ],
      "metadata": {
        "id": "GZTA_u6HX3ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([4,5,6])\n",
        "a=b;a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQhjcELRkCPG",
        "outputId": "eacd36f3-9bbe-4cc4-96df-57e6aa3a21c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([4,5,6])\n",
        "a[...]=b;a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46WVHXrIkQUC",
        "outputId": "869ab379-ad8c-4259-cd4a-9efd7dfba823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a에는 모두 [4,5,6]이 할당됨\n",
        "# 두경우, A가 가리키는 메모리의 위치가 서로 다름\n",
        "# 생략기호를 이요하여 변수의 메모리 주소를 고정할 수 있음\n",
        "# 메모리 주소를 고정함으로써 인스턴스 변수 grads를 다루기가 더 쉬워짐\n",
        "# grads리스트에는 각 매개변수의 기울기를 저장함. 생략기호를 사용하므로 이 넘파이 배열의 메모리 주소가 변하는 일 없이 항상 값을 덮어씀\n",
        "# 이렇게 하면 기울기를 그룹화하는 작업을 최초에 한번만 하면 된다는 이점이 생김\n"
      ],
      "metadata": {
        "id": "bafeY0NWhYDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기울기의 도출과 역전파 구현\n",
        "# 1. sigmoid계층\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.params , self.grads =[],[]\n",
        "    self.out = None \n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = 1/(1+np.exp(-x))\n",
        "    self.out = out \n",
        "    return out \n",
        "  \n",
        "  def backward(self, dout) : \n",
        "    dx = dout * (1-self.out) * self.out \n",
        "    return dx  \n",
        "  "
      ],
      "metadata": {
        "id": "RhiD0wQ31rhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# affine 계층\n",
        "# 순전파 : y=np.matmul(x,W)+b\n",
        "# 편향을 더할때는 넘파이의 브로드캐스트가 사용됨\n",
        "class Affine:\n",
        "  def __init__(self,W,b):\n",
        "    self.params = [W,b]\n",
        "    self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "    self.x = None\n",
        "\n",
        "  def forward(self,x):\n",
        "    W,b = self.params\n",
        "    out = np.matmul(x,W) + b\n",
        "    self.x = x\n",
        "    return out \n",
        "  \n",
        "  def backward(self, dout):\n",
        "    W,b = self.params\n",
        "    dx = np.matmul(dout, W.T) \n",
        "    dW = np.matmul(self.x.T, dout)\n",
        "    db = np.sum(dout, axis = 0)\n",
        "    self.grads[0][...] = dW \n",
        "    self.grads[1][...] = db \n",
        "    return dx \n",
        "\n"
      ],
      "metadata": {
        "id": "64Fgwilz2JbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# soft max with loss 계층\n",
        "#소프트 맥스함수와 교차 엔트로피 오차는 하나의 계층으로 구현할 것\n"
      ],
      "metadata": {
        "id": "QO_amO3tkua3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD구현\n",
        "class SGD:\n",
        "  def __init__(self, lr=0.01):\n",
        "    self.lr = lr\n",
        "  \n",
        "  def update(self, params, grads):\n",
        "    for i in range(len(params)):\n",
        "      params[i] -= self.lr * grads[i]\n",
        "      "
      ],
      "metadata": {
        "id": "eJGMzkKyOxKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EMKT6xQlO-zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbJvA1-RXgNO",
        "outputId": "bf31088f-e051-4423-d5bb-b7b58d4b5f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sys.path.append('/content/deep-learning-from-scratch-2')"
      ],
      "metadata": {
        "id": "eh1thlxMZIzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJCDCxFjXxBV",
        "outputId": "1413a654-bec1-4cee-d962-8d1536aa6978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dataset\n",
            "  Downloading dataset-1.5.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting banal>=1.0.1\n",
            "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from dataset) (1.4.31)\n",
            "Collecting alembic>=0.6.2\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic>=0.6.2->dataset) (4.11.1)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.2->dataset) (1.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (3.10.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.0.1)\n",
            "Installing collected packages: Mako, banal, alembic, dataset\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 banal-1.0.6 dataset-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import spiral  "
      ],
      "metadata": {
        "id": "EowZsxxCXrQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "x,t = spiral.load_data()\n",
        "\n",
        "print('x', x.shape)\n",
        "print('t', t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyWC0AfiXu94",
        "outputId": "36d5dbbf-5fd3-4092-881b-a5560d7e293d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x (300, 2)\n",
            "t (300, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from common.layers import Affine, Sigmoid, SoftmaxWithLoss\n",
        "\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    I,H,O = input_size, hidden_size, output_size \n",
        "    #가중치와 편향초기화\n",
        "    W1 = 0.01 * np.random.randn(I,H)\n",
        "    b1 = np.zeros(H)\n",
        "    W2 = 0.01 * np.random.randn(H,O)\n",
        "    b2 = np.zeros(0)\n",
        "\n",
        "    # 계층생성\n",
        "    self.layers = [Affine(W1, b1), Sigmoid(), Affine(W2,b2)]\n",
        "    self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "    # 모든 가중치와 기울기를 리스트에 모음\n",
        "    self.params , self.grads = [], []\n",
        "    for layer in self.layers : \n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads \n",
        "\n",
        "  def predic(self, x):\n",
        "    for layer in self.layers : \n",
        "      x = layer.forward(x)\n",
        "    return x \n",
        "  \n",
        "\n",
        "  def forward(self, x, t):\n",
        "    score = self.predict(x)\n",
        "    loss = self.loss_layer.forward(score,t)\n",
        "    return loss  \n",
        "  \n",
        "  def backward(self, dout=1): \n",
        "    dout = self.loss_layer.backward(dout) \n",
        "    for layer in reversed(self.layers):\n",
        "      dout = layer.backward(dout) \n",
        "    return dout \n"
      ],
      "metadata": {
        "id": "83Zh5_MqY49C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 코드\n"
      ],
      "metadata": {
        "id": "R8Cnx9m8e4xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch2. 자연어와 단어의 분산 표현 "
      ],
      "metadata": {
        "id": "SB_WL3m1fl1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어의 의미 이해시키기\n",
        "# 1. 시소러스를 활용한 기법(유의어 사전활용)\n",
        "# 2. 통계 기반기법\n",
        "# 3. 추론기반기법(word2vec)\n"
      ],
      "metadata": {
        "id": "XC4ZbVG-fpL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.시로러스 활용\n",
        "# car=auto = automobile machine \n",
        "# 단어사이의 연결을 정의\n",
        "# 단어 네트워크를 이용하여 컴퓨터에게 단어 사이의 관계를 가르침\n",
        "# 워드넷 : 자연어 처리 분야에서 가장 유명한 시소러스/ 프린스턴 대학에서 1985년부터 구축하기 시작\n",
        "# 유의어를 얻거나 단어 네트워크를 이용할 수 있음\n",
        "# NLKT모듈을 설치하고 간단한 실험을 해볼예정\n",
        "# 시소러스의 문제점 : 단어의 의미를 사람이 수작업으로 레이블링하는 방식 : 시대변화에 대응하기 어려움, 사람을 쓰는 비용이 큼, 단어의 미묘한 차이를 표현할 수 없음(레트로, 빈티지)\n"
      ],
      "metadata": {
        "id": "StkHTKjmgEAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.통계 기반 기법\n",
        "# 말뭉치(CORPUS)\n",
        "# "
      ],
      "metadata": {
        "id": "FHQ_Mj6eg5cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이썬으로 말뭉치 전처리하기\n",
        "text= 'you say goodbye and i say hello.'\n",
        "text=text.lower()\n",
        "text= text.replace('.',' .')\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qBSJE270hAFQ",
        "outputId": "4fb5a433-eac7-4552-dc3d-f766a81e8741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'you say goodbye and i say hello .'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split(' ')"
      ],
      "metadata": {
        "id": "9zdyeKEAgow6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDp1x4sHhOy3",
        "outputId": "ce3a0aab-e9f8-4d9b-a1a5-fc7628ee169b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_id ={}\n",
        "id_to_word = {}\n",
        "for word in words:\n",
        "  if word not in word_to_id:\n",
        "    new_id = len(word_to_id) \n",
        "    word_to_id[word] = new_id \n",
        "    id_to_word[new_id] = word "
      ],
      "metadata": {
        "id": "fCP3BdZohPUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_to_id) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePPuK0iFog_c",
        "outputId": "430cf228-cf5d-4a29-b13e-7e65b5bdc0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj0T23dhhiI_",
        "outputId": "0cf50bce-d136-451b-efed-665613be969c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9tQonUJhnFz",
        "outputId": "6106f869-3338-426c-bec2-065e94b6c5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 6, 'and': 3, 'goodbye': 2, 'hello': 5, 'i': 4, 'say': 1, 'you': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_word[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1PhA5UJjhobX",
        "outputId": "48ab07a2-73fd-43dc-d892-844846175879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'say'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_id['hello']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1zzmMLcX6_p",
        "outputId": "c5dc734a-9377-4d5f-f547-d43eb14e6875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_eTHVsrYJmJ",
        "outputId": "3dd42400-2e0d-44d2-c320-45f702bb66fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어목록을 단어 id목록으로 변경\n",
        "import numpy as np \n",
        "corpus = [word_to_id[w] for w in words] ;corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SgLNTkBX91B",
        "outputId": "5ca94ab2-05ea-4a75-8310-d9d19467d15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 1, 5, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 내포\n",
        "# 리스트나 딕셔너리 등의 반복문 처리를 간단하게 쓰기 위한기법\n",
        "xs = [1,2,3,4]\n",
        "[x**2 for x in xs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_J_Z1VQYMzi",
        "outputId": "3e1834a9-88e4-483c-a6da-527a49bb74aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 말뭉치를 이용하기 위한 사전준비 마침\n",
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('.', ' .')\n",
        "  words = text.split(' ')\n",
        "  word_to_id ={}\n",
        "  id_to_word ={}\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "      id_to_word[new_id] = word \n",
        "  corpus = np.array([word_to_id[w] for w in words])  \n",
        "  return corpus, word_to_id, id_to_word"
      ],
      "metadata": {
        "id": "koN3bNE6YZFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)"
      ],
      "metadata": {
        "id": "2RjN9rtYY8vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M64Rp5AlZFFl",
        "outputId": "ec25dadc-74ee-4dcf-e975-9d943ca3fafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 1, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfUzTaXGZF3n",
        "outputId": "605f72f8-f81b-4100-d6f1-825f9b4d8bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 6, 'and': 3, 'goodbye': 2, 'hello': 5, 'i': 4, 'say': 1, 'you': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIXyw6qhZG7w",
        "outputId": "16d93f6e-a053-49ef-b1c9-c31d7db21510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어의 분산표현 : 단어를 고정길이의 밀집벡터로 변환\n",
        "# 분포가설\n",
        "# 단어를 벡터로 표현하는 연구는 수없이 이뤄져 왔음\n",
        "# 하나의 간단한 아이디어에 뿌리를 두고있음: 단어의 의미는 주변단어에 의해 형성된다는 점(분포가설)\n",
        "# 단어자체는 의미가 없고, 그 단어가 사용된 맥락이 의미를 형성함\n",
        "# i drink wine / we drink wine\n",
        "# i guzzle beer / we guzzle wine"
      ],
      "metadata": {
        "id": "iwkqu_UoZHt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동시발생 행렬\n",
        "# 어떤단어에 주목할때, 주변에 어떤단어가 몇번이나 등장하는지를 세어 집계하는 방식\n",
        "import sys\n",
        "sys.path.append('/content/deep-learning-from-scratch-2')\n",
        "from common.util import preprocess"
      ],
      "metadata": {
        "id": "UTpvh0zJbBPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)"
      ],
      "metadata": {
        "id": "3slCadwMbVhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# co-occurance matrix\n",
        "C=np.array([\n",
        "    [0,1,0,0,0,0,0],\n",
        "    [1,0,1,0,1,1,0],\n",
        "    [0,1,0,1,0,0,0],\n",
        "    [0,0,1,0,1,0,0],\n",
        "    [0,1,0,1,0,0,0],\n",
        "    [0,1,0,1,0,0,1],\n",
        "    [0,0,0,0,0,1,0],\n",
        "], dtype=np.int32\n",
        ")"
      ],
      "metadata": {
        "id": "ybk-E5mqbjKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK7XRcNpcIef",
        "outputId": "c7ab907a-7f19-42f6-c272-16c66a909720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(C[0]) #id가 0인 단어의 벡터표현"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNQDbuaqcX_0",
        "outputId": "2bd1cc68-e4aa-4e54-fd85-4e73b2c8dd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(C[4])# id가 4인 단어의 벡터표현"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On0ABN97cafo",
        "outputId": "b644a20a-5479-47bf-b9ad-2fb223769c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(C[word_to_id['goodbye']]) # goodbye의 벡터표현"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_dMvjoEcb-A",
        "outputId": "206b3c74-5486-43f9-efb0-9ab79a4bcbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 동시발생행렬 자동으로 만들기 \n",
        "# 말뭉치로부터 동시 발생 행렬을 만들어주는 함수구현하기\n",
        "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
        "  corpus_size = len(corpus)\n",
        "  co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32) # 0으로 만든 2차원 배열로 초기화\n",
        "\n",
        "  for idx , word_id in enumerate(corpus):\n",
        "      for i in range(i, window_size+1) :\n",
        "        left_idx = idx-i\n",
        "        rigth_idx = idx+i\n",
        "        if left_idx >= 0:\n",
        "          left_word_id = corpus[left_idx]\n",
        "          co_matrix[word_id, left_word_id] += 1\n",
        "        if rigth_idx < corpus_size:\n",
        "          rigth_word_id = corpus[rigth_idx]\n",
        "          co_matrix[word_id, right_word_id] += 1\n"
      ],
      "metadata": {
        "id": "YC846a6jcfNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터간 유사도: 코사인 유사도 사용\n",
        "# 코사인 유사도를 직관적으로 풀어보자면 두 벡터가 가르키는 방향이 얼마나 비슷한가, \n",
        "def cos_similarty(x,y):\n",
        "  nx =  x/np.sqrt(np.sum(x**2))\n",
        "  ny = y/np.sqrt(np.sum(y**2))\n",
        "  return np.dot(nx, ny)"
      ],
      "metadata": {
        "id": "Go2pmyxffBgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similarty(x,y, eps = 1e-8): # 0으로 나누는 사태를 방지해줌\n",
        "  nx =  x/np.sqrt(np.sum(x**2)+eps)\n",
        "  ny = y/np.sqrt(np.sum(y**2)+eps)\n",
        "  return np.dot(nx, ny)"
      ],
      "metadata": {
        "id": "U2d7GWn3fsG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you 와 i의 유사도 구하기\n",
        "from common.util import preprocess, create_co_matrix, cos_similarity "
      ],
      "metadata": {
        "id": "8Y_ijNCmfz34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)"
      ],
      "metadata": {
        "id": "_inDgiBjgLjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_id)\n"
      ],
      "metadata": {
        "id": "HabLAShtgLmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C= create_co_matrix(corpus, vocab_size)"
      ],
      "metadata": {
        "id": "NOC4TMkLgAF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c6cJTdvgF2N",
        "outputId": "c4031fcb-ab49-49ce-a9b4-b293329721f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c0 = C[word_to_id['you']]\n",
        "c1 = C[word_to_id['i']]"
      ],
      "metadata": {
        "id": "gCaAqJEugSuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cos_similarity(c0,c1)) # high"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZPGM9ocgY5t",
        "outputId": "55c945e4-3201-4cd5-9a30-349753252847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7071067691154799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사 단어의 랭킹표시\n",
        "# 그 검색어와 비슷한 단어를 유사도 순으로 출력하는 함수\n",
        "# 구성 : most_similar(query, word_to_id, id_to_word, word_matrix, top=5)\n",
        "# query : 검색어\n",
        "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
        "  # 검색어를 꺼낸다 / 검색어의 단어벡터를 꺼낸다\n",
        "  if query not in word_to_id:\n",
        "    print('%s 를 찾을 수 없습니다'% query)\n",
        "    return\n",
        "  \n",
        "  print('\\n[query] ' + query)\n",
        "  query_id = word_to_id[query]\n",
        "  query_vec = word_matrix[query_id]\n",
        "\n",
        "  # 코사인 유사도 계산 / 검색어의 단어벡터와 다른 모든 단어 벡터와의 코사인 유사도를 각각 구한다\n",
        "  vocab_size = len(id_to_word) \n",
        "  similarity = np.zeros(vocab_size) #초기화\n",
        "  for i in range(vocab_size):\n",
        "    similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
        "  \n",
        "  # 코사인 유사도를 기준으로 내림차순으로 출력\n",
        "  count = 0\n",
        "  for i in (-1 * similarity).argsort():\n",
        "    if id_to_word[i] == query :\n",
        "      continue\n",
        "    \n",
        "    print('%s : %s' %(id_to_word[i], similarity[i]))\n",
        "    count +=1\n",
        "    \n",
        "    if count >= top:\n",
        "      return"
      ],
      "metadata": {
        "id": "nx3XKREsgcsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= np.array([100,-20,2]) "
      ],
      "metadata": {
        "id": "gPRWqtmJkdmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.argsort() #오름차순으로 정렬 index로 표시함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_KyFO8-kVSy",
        "outputId": "848ab515-6241-4c8e-c9f4-b751ed7726d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(-x).argsort() # 역순임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkrABpkakiG0",
        "outputId": "5ed3de9e-2f8c-4822-8e2b-786f20b181e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar('you', word_to_id, id_to_word, C, top=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaCwJvlcksf-",
        "outputId": "5e4e4ca1-6c78-4c59-e2b8-8755b77b4af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[query] you\n",
            "goodbye : 0.7071067691154799\n",
            "i : 0.7071067691154799\n",
            "hello : 0.7071067691154799\n",
            "say : 0.0\n",
            "and : 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 통계 기반 기법 개선하기\n",
        "# 점별 상호 정보량 (PMI) 라는 척도를 사용 Pointwise mutual information \n",
        "# pmi는 확률변수 x 와 y에 대해 다음식으로 정의 \n",
        "# pmi(x,y) = log2 [(p(x,y) / p(x)p(y))]\n",
        "# pmi값이 높을수록 관련성이 높다는 의미\n",
        "# p(x) : 단어 x가 말뭉치에 등장할 확률의미\n",
        "# p(x,y) : 단어 x,y가 동시에 발생할 확률\n",
        "# p(x,y) = C(x,y) / N \n",
        "# C(x,y) : x,y가 동시발생한 횟수\n",
        "# N : 말뭉치에 포함된 단어수\n",
        "# 단어가 단독으로 출현하는 횟수가 고려된 값임\n",
        "# the같은경우, 자주출현하게 되면서 pmi점수가 낮아짐\n",
        "# pmi의 문제점 : 두 단어의 동시발생횟수가 0이면 -무한대가 된다는 점\n",
        "# 이 문제를 해결하기 위해 ppmi(양의 상호 정보량)을 사용\n",
        "# ppmi(x,y) = max(0, pmi(x,y))\n"
      ],
      "metadata": {
        "id": "O1A-3w20k3Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ppmi(C, verbose=False, eps = 1e-8):  # C : 동시발생 행렬, VERBOSE는 진행사항 출력여부를 결정하는 플래그\n",
        "  M = np.zeros_like(C, dtype = np.float32) \n",
        "  N = np.sum(C)\n",
        "  S = np.sum(C,axis=0)\n",
        "  total =C.shape[0] * C.shape[1] \n",
        "  cnt = 0\n",
        "\n",
        "  for i in range(C.shape[0]):\n",
        "    for j in range(C.shape[1]):\n",
        "      pmi = np.log2(C[i,j] *N / (S[j]*S[i]) + eps)\n",
        "      M[i,j] = max(0, pmi)\n",
        "      \n",
        "      if verbose:\n",
        "        cnt+=1\n",
        "        if cnt%(total//100+1) ==0:\n",
        "          print('%.1f%% 완료'%(100*cnt/total))\n",
        "  return M\n",
        "      "
      ],
      "metadata": {
        "id": "wbbhSDp7lIZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text= 'you say goodbye and i say hello.'\n",
        "corpus , word_to_id, id_to_word = preprocess(text)"
      ],
      "metadata": {
        "id": "tAsl1JbMs_-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_id)\n",
        "C= create_co_matrix(corpus, vocab_size)\n",
        "W= ppmi(C);W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmaWu4jotDtq",
        "outputId": "755f3019-11eb-4e18-f520-bb4c4afdad67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.       , 1.8073549, 0.       , 0.       , 0.       , 0.       ,\n",
              "        0.       ],\n",
              "       [1.8073549, 0.       , 0.8073549, 0.       , 0.8073549, 0.8073549,\n",
              "        0.       ],\n",
              "       [0.       , 0.8073549, 0.       , 1.8073549, 0.       , 0.       ,\n",
              "        0.       ],\n",
              "       [0.       , 0.       , 1.8073549, 0.       , 1.8073549, 0.       ,\n",
              "        0.       ],\n",
              "       [0.       , 0.8073549, 0.       , 1.8073549, 0.       , 0.       ,\n",
              "        0.       ],\n",
              "       [0.       , 0.8073549, 0.       , 0.       , 0.       , 0.       ,\n",
              "        2.807355 ],\n",
              "       [0.       , 0.       , 0.       , 0.       , 0.       , 2.807355 ,\n",
              "        0.       ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=3) # 유효숫자 3자리보기"
      ],
      "metadata": {
        "id": "PZS5JxePuYMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('동시발생확률')\n",
        "print(C)\n",
        "print('-'*50)\n",
        "print('PPMI')\n",
        "print(W)\n",
        "# 동시발생행렬을 PPMI행렬로 변환하는 것 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-dz1-L_ud5y",
        "outputId": "2a7899b6-d6fc-4c5b-8c5e-cf7addc5a99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "동시발생확률\n",
            "[[0 1 0 0 0 0 0]\n",
            " [1 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0]]\n",
            "--------------------------------------------------\n",
            "PPMI\n",
            "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.807 0.    0.    0.    0.    2.807]\n",
            " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PPMI행렬에도 여전히 문제가 존재함 말뭉치의 어휘수가 증가함에 따라 각 단어 벡터의 차원수도 증가함\n",
        "# 말뭉치의 어휘수가 10만개라면 그 벡터의 차원수도 똑같이 10만"
      ],
      "metadata": {
        "id": "lavPp_S1ul8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터의 차원감소\n",
        "# 중요한 정보는 최대한 유지하면서 줄이는게 핵심\n",
        "# 특이값분해 (SVD)를 이용한 차원축소\n",
        "# X = USV\n",
        "# U,V : 직교행렬, S: 대각행렬\n",
        "# U행렬은 단어 공간으로 취급할 수 있음\n",
        "# S행렬은 대학행렬로 대각성분에는 특잇값이 큰 순서로 나열되어 있음, 해당축의 중요도로 간주-> 중요도가 낮은 원소를 깍아내는 방법을 생각할 수 있음\n"
      ],
      "metadata": {
        "id": "Bo6LZGbju6tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD에 의한 차원 감소\n",
        "U,S,V = np.linalg.svd(W)"
      ],
      "metadata": {
        "id": "Ov6Af5lRvWSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(C[0])\n",
        "print(W[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6hbpWw76-2j",
        "outputId": "5e1801df-dd80-413d-c7f4-8f06308abfed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 0 0]\n",
            "[0.    1.807 0.    0.    0.    0.    0.   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(U[0]) # 희소벡터인 w[0]가 svd에 의해서 밀집벡터로 변함\n",
        "print(U[0,:2]) # 2차원 벡터로 줄임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irnyqGzg7BOh",
        "outputId": "dc03f3f2-4b75-485b-d61e-335102534927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.110e-16  3.409e-01 -4.163e-16 -1.205e-01 -1.110e-16 -9.323e-01\n",
            " -1.086e-16]\n",
            "[-1.110e-16  3.409e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_id.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssh4vQBF8XFh",
        "outputId": "d8523111-2ff9-435d-e2ff-298f556c422e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('you', 0), ('say', 1), ('goodbye', 2), ('and', 3), ('i', 4), ('hello', 5), ('.', 6)])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "for word, word_id in word_to_id.items():\n",
        "  plt.annotate(word, (U[word_id,0], U[word_id,1]))\n",
        "\n",
        "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
        "plt.show()\n",
        "# 행렬의 크기가 N이면 연산은 O(N^3)이 걸림 계산량이 N의 3제곱에 비례해 늘어남\n",
        "# Truncated SVD같은 더 빠른 기법이 사용됨(특이값이 작은것은 버림, 사이킥런의 Truncated SVM사용가능)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NRkkiCee7DtE",
        "outputId": "3d05a87f-7413-4571-c1f8-0ede2a8d040f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PTB 데이터\n",
        "# 지금까지는 아주 작은 텍스트 데이터를 말뭉치로 사용함\n",
        "# 펜 트리뱅크 데이터셋(PENN TREEBANK) : 주어진 기법의 품질을 측정하는 벤치마크로 자주 이용됨\n",
        "# WORD2VEC의 발명자인 토마스 미콜로프의 웹페이지에서 받을 수 있음\n",
        "# 희소한 단어를 <UNK>라는 특수문자로 치환하거나 구체적인 숫자를 N으로 대체하는 등의 작업이 적용됨\n"
      ],
      "metadata": {
        "id": "eQLpYepj7xiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import ptb"
      ],
      "metadata": {
        "id": "95L3H0Nx-B16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus, word_to_id, id_to_word = ptb.load_data('train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pul7lz3j-EVs",
        "outputId": "e531eb3f-f03f-4da7-b14e-7e530bba261e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ptb.train.txt ... \n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('말뭉치크기', len(corpus))\n",
        "print('corpus[:30]', corpus[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uINTHy7A-Ja1",
        "outputId": "8e8c5c6b-767f-452f-8f34-ff03b77f0624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "말뭉치크기 929589\n",
            "corpus[:30] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(id_to_word[0])\n",
        "print(id_to_word[1])\n",
        "print(id_to_word[2])\n",
        "\n",
        "\n",
        "print(word_to_id['car'])\n",
        "print(word_to_id['happy'])\n",
        "print(word_to_id['lexus'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eaCONjr-Q65",
        "outputId": "bc1917f9-0173-4c30-88df-20da95dbb2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aer\n",
            "banknote\n",
            "berlitz\n",
            "3856\n",
            "4428\n",
            "7426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ptb데이터셋 평가 \n",
        "# ptb데이터셋에 통계기반 기법을 적용해보기\n",
        "# 이번에틑 큰 행렬에 svd를 적용해야하므로 고속 svd이용(sklearn) / 간단한np.linalg.svd()도 있음\n",
        "window_size= 2\n",
        "wordvec_size=100\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "print('동시발생수 계산 ..')\n",
        "C= create_co_matrix(corpus, vocab_size, window_size) ;C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0_tKz6F-cmk",
        "outputId": "d65836a9-5432-4a04-a2aa-f6a72a5bff07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "동시발생수 계산 ..\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 0, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('PPMI계산...')\n",
        "W= ppmi(C, verbose=True); W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQviuolK-_tw",
        "outputId": "e65c0ffa-bc2c-44c3-c98a-541c6c9326fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPMI계산...\n",
            "1.0% 완료\n",
            "2.0% 완료\n",
            "3.0% 완료\n",
            "4.0% 완료\n",
            "5.0% 완료\n",
            "6.0% 완료\n",
            "7.0% 완료\n",
            "8.0% 완료\n",
            "9.0% 완료\n",
            "10.0% 완료\n",
            "11.0% 완료\n",
            "12.0% 완료\n",
            "13.0% 완료\n",
            "14.0% 완료\n",
            "15.0% 완료\n",
            "16.0% 완료\n",
            "17.0% 완료\n",
            "18.0% 완료\n",
            "19.0% 완료\n",
            "20.0% 완료\n",
            "21.0% 완료\n",
            "22.0% 완료\n",
            "23.0% 완료\n",
            "24.0% 완료\n",
            "25.0% 완료\n",
            "26.0% 완료\n",
            "27.0% 완료\n",
            "28.0% 완료\n",
            "29.0% 완료\n",
            "30.0% 완료\n",
            "31.0% 완료\n",
            "32.0% 완료\n",
            "33.0% 완료\n",
            "34.0% 완료\n",
            "35.0% 완료\n",
            "36.0% 완료\n",
            "37.0% 완료\n",
            "38.0% 완료\n",
            "39.0% 완료\n",
            "40.0% 완료\n",
            "41.0% 완료\n",
            "42.0% 완료\n",
            "43.0% 완료\n",
            "44.0% 완료\n",
            "45.0% 완료\n",
            "46.0% 완료\n",
            "47.0% 완료\n",
            "48.0% 완료\n",
            "49.0% 완료\n",
            "50.0% 완료\n",
            "51.0% 완료\n",
            "52.0% 완료\n",
            "53.0% 완료\n",
            "54.0% 완료\n",
            "55.0% 완료\n",
            "56.0% 완료\n",
            "57.0% 완료\n",
            "58.0% 완료\n",
            "59.0% 완료\n",
            "60.0% 완료\n",
            "61.0% 완료\n",
            "62.0% 완료\n",
            "63.0% 완료\n",
            "64.0% 완료\n",
            "65.0% 완료\n",
            "66.0% 완료\n",
            "67.0% 완료\n",
            "68.0% 완료\n",
            "69.0% 완료\n",
            "70.0% 완료\n",
            "71.0% 완료\n",
            "72.0% 완료\n",
            "73.0% 완료\n",
            "74.0% 완료\n",
            "75.0% 완료\n",
            "76.0% 완료\n",
            "77.0% 완료\n",
            "78.0% 완료\n",
            "79.0% 완료\n",
            "80.0% 완료\n",
            "81.0% 완료\n",
            "82.0% 완료\n",
            "83.0% 완료\n",
            "84.0% 완료\n",
            "85.0% 완료\n",
            "86.0% 완료\n",
            "87.0% 완료\n",
            "88.0% 완료\n",
            "89.0% 완료\n",
            "90.0% 완료\n",
            "91.0% 완료\n",
            "92.0% 완료\n",
            "93.0% 완료\n",
            "94.0% 완료\n",
            "95.0% 완료\n",
            "96.0% 완료\n",
            "97.0% 완료\n",
            "98.0% 완료\n",
            "99.0% 완료\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.   , 19.241, 18.826, ...,  0.   ,  0.   ,  0.   ],\n",
              "       [19.241,  0.   , 18.241, ...,  0.   ,  0.   ,  0.   ],\n",
              "       [18.826, 18.241,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
              "       ...,\n",
              "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
              "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
              "       [ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('svd계산 ...')\n",
        "try :\n",
        "  # truncatedsvd 빠름! \n",
        "  from sklearn.utils.extmath import randomized_svd \n",
        "  U,S,V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)  \n",
        "except ImportError:\n",
        "  # SVD\n",
        "  U,S,V = np.linalg.svd(W) \n",
        "\n",
        "word_vecs = U[:, :wordvec_size] \n",
        "querys = ['you', 'year','car','toyota'] \n",
        "for query in querys :  \n",
        "  most_similar(query, word_to_id, id_to_word, word_vecs, top=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF8FZdL9BQ0W",
        "outputId": "64affc73-8fc3-4bd6-acef-e3028c4d298a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svd계산 ...\n",
            "\n",
            "[query] you\n",
            "i : 0.6798784136772156\n",
            "we : 0.6585314869880676\n",
            "'ll : 0.5424599051475525\n",
            "do : 0.5095625519752502\n",
            "'d : 0.49672359228134155\n",
            "\n",
            "[query] year\n",
            "month : 0.7190585136413574\n",
            "earlier : 0.6854026913642883\n",
            "quarter : 0.6749022006988525\n",
            "last : 0.6479121446609497\n",
            "fiscal : 0.5858595967292786\n",
            "\n",
            "[query] car\n",
            "auto : 0.6217397451400757\n",
            "luxury : 0.58762526512146\n",
            "cars : 0.5173414945602417\n",
            "domestic : 0.4970399737358093\n",
            "truck : 0.4700299799442291\n",
            "\n",
            "[query] toyota\n",
            "motor : 0.7230758666992188\n",
            "motors : 0.682379424571991\n",
            "honda : 0.6747257709503174\n",
            "nissan : 0.6588114500045776\n",
            "lexus : 0.6090384721755981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nwRc1HT-CBs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch3. word2vec "
      ],
      "metadata": {
        "id": "klRm-_6ocT4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞에서 통계기반 기법으로 분산표현을 얻음, 이번에는 추론기반기법을 사용\n",
        "# 추론기법과정에서 신경망을 활용함\n",
        "# 단순한 word2vec구하는 과정\n",
        "# 단어를 벡터로 표현하는 방법은 지금까지 활발히 연구됨, \n",
        "# 통계기반기법과 추론기법 : 단어의 의미를 얻는 방식은 서로 크게 다르지만, 그 배경에는 모두 분포가설이 있음"
      ],
      "metadata": {
        "id": "FiqdxUXXcV5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 통계기반 기법의 문제점:계산량이 너무 큼\n",
        "# 통계기반기법 : 학습데이터를 한꺼번에 처리(배치학습)\n",
        "# 추론기법 : 학습데이터의 일부를 사용하여 순차적으로 학습(미니배치 학습), 여러 머신과 여러 GPU를 이용한 병렬 계산도 가능함 -> 학습속도 높임\n",
        "# 추론 문제를 풀면서 단어의 출현 패턴을 학습 \n",
        "# 분포가설 : 단어의 의미는 주변 단어에 의해 형성된다는 가설\n",
        "# 단어의 동시 발생 가능성을 얼마나 잘 모델링 하는가가 중요한 연구 주제"
      ],
      "metadata": {
        "id": "h0pRVcuSc1kz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "c= np.array([[1,0,0,0,0,0,0]])\n",
        "W=np.random.randn(7,3) # 가중치\n",
        "h= np.matmul(c,W);h\n",
        "# id가 0인 단어를 원핫 표현으로 표현한 다음 완전 연결계층을 통과시켜 변환하는 보여줌\n"
      ],
      "metadata": {
        "id": "bceAA0MQdSdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a5bc88-fb44-4c1b-f12b-5b9e0bbce22f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.51366783, -0.1890562 , -0.90969628]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "sys.path.append('/content/deep-learning-from-scratch-2/')\n",
        "from common.layers import MatMul \n",
        "c= np.array([[1,0,0,0,0,0,0]])\n",
        "W= np.random.randn(7,3)\n",
        "layer = MatMul(W) \n",
        "h = layer.forward(c) \n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5jhb0d4OCsA",
        "outputId": "6eeb5447-797e-4a5d-a7cb-25c53fa2f4dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.31314808  0.35635513  1.38706403]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0PJ63rCSZrZ",
        "outputId": "cf9bafec-f897-4750-bc70-ccc0e2e02775"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<common.layers.MatMul at 0x7f249b0a0450>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6MKwDlhSfaO",
        "outputId": "dede448a-a18a-4ab6-9798-41cf893afffe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.79509471, -1.45923992, -0.02852232],\n",
              "       [-0.28726945,  0.54178468,  0.28341626],\n",
              "       [-0.72607232, -0.89912527, -0.40804838],\n",
              "       [-1.21088044,  0.39261912, -0.20378796],\n",
              "       [ 0.46259745,  2.09518604,  0.21846207],\n",
              "       [ 0.78681567,  1.45867321, -0.59498213],\n",
              "       [-0.73196487, -2.10235831,  1.20625192]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단순한 WORD2VEC \n",
        "# CBOW(continuous bag-of-words) \n",
        "# 맥락으로부터 타깃을 추측하는 용도의 신경망, 타깃은 중앙단어이고, 그 주변 단어들이 맥락이 됨\n",
        "# CBOW모델 구현하기\n",
        "c0 = np.array([[1,0,0,0,0,0,0]])\n",
        "c1 = np.array([[0,0,1,0,0,0,0]])\n",
        "W_in = np.random.randn(7,3)\n",
        "W_out = np.random.randn(3,7)\n",
        "in_layer0 = MatMul(W_in)\n",
        "in_layer1 = MatMul(W_in) \n",
        "out_layer = MatMul(W_out) \n",
        "\n",
        "# 순전파\n",
        "h0 = in_layer0.forward(c0) \n",
        "h1 = in_layer1.forward(c1) \n",
        "h = 0.5 * (h0+h1) \n",
        "s = out_layer.forward(h) \n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i00T4zdvShmW",
        "outputId": "5a076bc1-2bb3-4988-faf4-8e1e1f1961b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.36073538  0.5551377   0.20957163  0.17122678  0.08090242 -0.37807664\n",
            "   0.09402426]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CBOW 모델의 학습 \n",
        " # WORD2VEC 에서 사용되는 신경망에는 두가지 가중치가 있음 W_in , W_out \n",
        " # W_in 의 각 행이 각 단어의 분산 표현에 해당됨\n",
        " # 출력층 가중치 W_out에도 단어의 의미가 인코딩된 벡터가 저장되고 있다고 생각할 수 있음\n",
        " # 다만 출력 가중치는 단어의 분산표현이 열방향으로 저장됨\n",
        " # 최종적으로 이용하는 단어의 분산표현으로 선택가능한것 : 1. 입력층, 2. 출력층, 3. 양쪽 모두이용\n",
        " # word2vec에서는  입력층의 가중치만 이용한다가 가장 대중적인 선택\n",
        " # word2vec과 비슷한 gloVe 에서는 두 가중치를 더했을때 가장 좋은 결과를 얻음\n",
        " "
      ],
      "metadata": {
        "id": "PsfR6I_IZLgN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 준비\n",
        "import sys\n",
        "sys.path.append('/content/deep-learning-from-scratch-2/')\n",
        "from common.util import preprocess \n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus , word_to_id, id_to_word = preprocess(text) \n",
        "print(corpus) \n",
        "print(id_to_word) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jAvrPI9v4Cs",
        "outputId": "e68b5e9e-1b31-4a07-befd-915e046b2a21"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_contexts_target(corpus, window_size =1):\n",
        "  target = corpus[window_size :-window_size] \n",
        "  contexts=[]\n",
        "  \n",
        "  for idx in range(window_size, len(corpus)-window_size) :\n",
        "    cs = []\n",
        "    for t in range(-window_size, window_size +1) : \n",
        "      if t==0:\n",
        "        continue \n",
        "      cs.append(corpus[idx+t]) \n",
        "    contexts.append(cs) \n",
        "  \n",
        "  return np.array(contexts), np.array(target) \n"
      ],
      "metadata": {
        "id": "6vcrAJzAwq58"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr5jYkQXzWeS",
        "outputId": "bfb6c30b-7abe-4ba8-a549-769832f5f7a4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 1, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[1:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YllY9hG8zd5J",
        "outputId": "16ee3b5b-fec2-4b5c-9a15-aa4f9410550c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts, target = create_contexts_target(corpus, window_size =1) \n",
        "print(contexts) \n",
        "print(target)\n",
        "# 말뭉치로부터 맥락과 타깃을 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSA63txjyAO1",
        "outputId": "d8637ba3-dca9-4a05-ee62-985c2ded0687"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 2]\n",
            " [1 3]\n",
            " [2 4]\n",
            " [3 1]\n",
            " [4 5]\n",
            " [1 6]]\n",
            "[1 2 3 4 1 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 원핫 벡터로 표현하기\n",
        "#(6,2) -> (6,2,7)로 변환\n",
        "import sys \n",
        "from common.util import preprocess, create_contexts_target, convert_one_hot \n",
        "vocab_size = len(word_to_id) \n",
        "target = convert_one_hot(target, vocab_size) \n",
        "contexts = convert_one_hot(contexts, vocab_size) \n"
      ],
      "metadata": {
        "id": "EvsppJhKyHGp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbUVJLlS1Dkj",
        "outputId": "b268c90c-2448-4a21-b440-e953a31c0e06"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 1, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 1, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 1, 0, 0, 0],\n",
              "        [0, 1, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0]],\n",
              "\n",
              "       [[0, 1, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 1]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CBOW모델 구현\n",
        "class SimpleCBOW:\n",
        "  def __init__(self, vocab_size, hidden_size): \n",
        "    V,H = vocab_size, hidden_size \n",
        "    # 가중치 초기화\n",
        "    W_in = 0.01 * np.random.randn(V,H).astype('f')  # 실수타입으로 변환 float의 약자, 32비트 부동 소수점\n",
        "    W_out = 0.01 * np.random.randn(H,V).astype('f') \n",
        "\n",
        "    # 계층 생성\n",
        "    self.in_layer0 = MatMul(W_in) \n",
        "    self.in_layer1 = MatMul(W_in) \n",
        "    self.out_layer = MatMul(W_out)\n",
        "    self.loss_layer = SoftmaxWithLoss() \n",
        "\n",
        "    # 모든 가중치와 기울기를 리스트에 모은다\n",
        "    layers = [self.in_layer0, self.in_layer1, self.out_layer] \n",
        "    for layer in layers: \n",
        "      self.params += layer.params \n",
        "      self.grads += layer.grads \n",
        "    \n",
        "    # 인스턴스 변수에 단어의 분산 표현을 저장함\n",
        "    self.word_vecs = W_in \n"
      ],
      "metadata": {
        "id": "IxpjUxO21Hke"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otv5pagF3WHN",
        "outputId": "f0443335-7a64-4c6e-d892-9bad6f510a50"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 1, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 1, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 1, 0, 0, 0],\n",
              "        [0, 1, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0]],\n",
              "\n",
              "       [[0, 1, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 1]]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYYNGCa53Mtp",
        "outputId": "da46d1f7-1863-4e1f-d179-3ae63837b5fa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIOnAnOu3UGp",
        "outputId": "95756d3a-2ae4-4c95-e661-5eb220ef5780"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, contexts,  target):\n",
        "  h0 = self.in_layer0.forward(contexts[:,0]) \n",
        "  h1 = self.in_layer1.forward(contexts[:,1]) \n",
        "  h = (h0+h1) / 2\n",
        "  score = self.out_layer.forward(h) \n",
        "  loss = self.loss_layer.forward(score, target) \n",
        "  return loss "
      ],
      "metadata": {
        "id": "jyT40AIf2CKq"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target # 2차원"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ3p4Vzg3hNo",
        "outputId": "9afd35c9-f9e3-4f66-cc2e-b4e220220c5c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 역전파\n",
        "def backward(self, dout=1): \n",
        "  ds = self.loss_layer.backward(dout) \n",
        "  da = self.out_layer.backward(ds) \n",
        "  da *= 0.5\n",
        "  self.in_layer1.backward(da) \n",
        "  self.in_layer0.backward(da) \n",
        "  return None "
      ],
      "metadata": {
        "id": "QbDZcXtr3sbs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from common.trainer import Trainer \n",
        "from common.optimizer import Adam \n",
        "from ch03.simple_cbow import SimpleCBOW \n",
        "from common.util import preprocess, create_contexts_target, convert_one_hot \n",
        "\n",
        "window_size = 1 \n",
        "hidden_size =5\n",
        "batch_size = 3 \n",
        "max_epoch = 1000\n",
        "\n",
        "model = SimpleCBOW(vocab_size,  hidden_size) \n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer) \n",
        "trainer.fit(contexts, target, max_epoch, batch_size) \n",
        "trainer.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nq7Jrcv-3qv3",
        "outputId": "219b1eca-7fdc-48c1-b3a1-0f7ee632cd79"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| 에폭 1 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 2 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 3 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 4 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 5 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 6 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 7 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 8 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 9 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 10 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 11 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 12 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 13 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 14 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 15 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 16 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 17 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 18 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 19 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 20 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 21 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 22 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 23 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 24 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 25 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 26 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 27 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 28 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 29 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 30 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 31 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 32 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 33 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 34 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 35 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 36 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 37 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 38 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 39 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 40 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 41 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 42 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 43 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 44 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 45 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 46 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 47 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 48 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 49 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 50 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 51 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 52 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 53 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 54 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 55 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 56 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 57 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 58 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 59 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 60 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 61 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 62 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 63 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 64 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 65 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 66 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 67 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 68 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 69 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 70 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 71 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
            "| 에폭 72 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
            "| 에폭 73 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
            "| 에폭 74 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 75 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 76 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
            "| 에폭 77 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 78 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
            "| 에폭 79 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 80 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
            "| 에폭 81 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 82 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 83 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 84 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 85 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 86 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 87 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 88 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 89 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 90 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 91 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
            "| 에폭 92 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 93 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
            "| 에폭 94 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 95 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 96 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 97 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
            "| 에폭 98 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
            "| 에폭 99 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
            "| 에폭 100 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 101 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 102 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
            "| 에폭 103 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 104 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 105 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 106 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
            "| 에폭 107 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 108 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 109 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 110 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 111 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 112 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 113 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 114 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 115 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 116 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 117 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 118 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 119 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 120 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
            "| 에폭 121 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
            "| 에폭 122 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
            "| 에폭 123 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
            "| 에폭 124 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
            "| 에폭 125 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
            "| 에폭 126 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
            "| 에폭 127 |  반복 1 / 2 | 시간 0[s] | 손실 1.58\n",
            "| 에폭 128 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
            "| 에폭 129 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 130 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
            "| 에폭 131 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 132 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 133 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
            "| 에폭 134 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
            "| 에폭 135 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 136 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 137 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 138 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
            "| 에폭 139 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 140 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
            "| 에폭 141 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 142 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 143 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 144 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 145 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
            "| 에폭 146 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 147 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
            "| 에폭 148 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
            "| 에폭 149 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
            "| 에폭 150 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 151 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
            "| 에폭 152 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 153 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
            "| 에폭 154 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
            "| 에폭 155 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
            "| 에폭 156 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
            "| 에폭 157 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 158 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 159 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 160 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 161 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 162 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
            "| 에폭 163 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
            "| 에폭 164 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 165 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 166 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 167 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
            "| 에폭 168 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
            "| 에폭 169 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 170 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
            "| 에폭 171 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 172 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
            "| 에폭 173 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 174 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 175 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
            "| 에폭 176 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 177 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 178 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 179 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 180 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 181 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 182 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 183 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
            "| 에폭 184 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 185 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 186 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 187 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 188 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 189 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
            "| 에폭 190 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 191 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 192 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 193 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 194 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 195 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
            "| 에폭 196 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 197 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 198 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
            "| 에폭 199 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 200 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 201 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 202 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
            "| 에폭 203 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 204 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 205 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 206 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 207 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 208 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 209 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 210 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 211 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 212 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 213 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 214 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 215 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 216 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 217 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 218 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
            "| 에폭 219 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 220 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 221 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 222 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 223 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 224 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 225 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
            "| 에폭 226 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 227 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 228 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 229 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 230 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 231 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 232 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 233 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 234 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
            "| 에폭 235 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 236 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 237 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 238 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 239 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 240 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 241 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 242 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 243 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 244 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 245 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 246 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 247 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 248 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 249 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 250 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 251 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 252 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 253 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 254 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 255 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 256 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 257 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 258 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 259 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 260 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 261 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 262 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 263 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 264 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 265 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 266 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 267 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 268 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 269 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 270 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 271 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 272 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 273 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 274 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 275 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 276 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 277 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 278 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 279 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 280 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 281 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 282 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 283 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 284 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 285 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 286 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 287 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 288 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 289 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 290 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 291 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 292 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 293 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 294 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 295 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 296 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 297 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 298 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 299 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 300 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 301 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 302 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 303 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 304 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 305 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 306 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 307 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 308 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 309 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 310 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 311 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 312 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 313 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 314 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 315 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 316 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 317 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 318 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 319 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 320 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 321 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 322 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 323 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 324 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 325 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 326 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 327 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 328 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 329 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 330 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 331 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 332 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 333 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 334 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 335 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 336 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 337 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 338 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 339 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 340 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 341 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 342 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 343 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 344 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 345 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 346 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 347 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 348 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 349 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 350 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 351 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 352 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 353 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 354 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 355 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 356 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 357 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 358 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 359 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 360 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 361 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 362 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 363 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 364 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 365 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 366 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 367 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 368 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 369 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 370 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 371 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 372 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 373 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 374 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 375 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 376 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 377 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 378 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 379 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 380 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 381 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 382 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 383 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 384 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 385 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 386 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 387 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 388 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 389 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 390 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 391 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 392 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 393 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 394 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 395 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 396 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 397 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 398 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 399 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 400 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 401 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 402 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 403 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 404 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 405 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 406 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 407 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 408 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 409 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 410 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 411 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 412 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 413 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 414 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 415 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 416 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 417 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 418 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 419 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 420 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 421 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 422 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 423 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 424 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 425 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 426 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 427 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 428 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 429 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 430 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 431 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 432 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 433 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 434 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 435 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 436 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 437 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 438 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 439 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 440 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 441 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 442 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 443 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 444 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 445 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 446 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 447 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 448 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 449 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 450 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 451 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 452 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 453 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 454 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 455 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 456 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 457 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 458 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 459 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 460 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 461 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 462 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 463 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 464 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 465 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 466 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 467 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 468 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 469 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 470 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 471 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 472 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 473 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 474 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 475 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 476 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 477 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 478 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 479 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 480 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 481 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 482 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 483 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 484 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 485 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 486 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 487 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 488 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 489 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 490 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 491 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 492 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 493 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 494 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 495 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 496 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 497 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 498 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 499 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 500 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 501 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 502 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 503 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 504 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 505 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 506 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 507 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 508 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 509 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 510 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 511 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 512 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 513 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 514 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 515 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 516 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 517 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 518 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 519 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 520 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 521 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 522 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 523 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 524 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 525 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 526 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 527 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 528 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 529 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 530 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 531 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 532 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 533 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 534 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 535 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 536 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 537 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 538 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 539 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 540 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 541 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 542 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 543 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 544 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 545 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 546 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 547 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 548 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 549 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 550 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 551 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 552 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 553 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 554 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 555 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 556 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 557 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 558 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 559 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 560 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 561 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 562 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 563 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 564 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 565 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 566 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 567 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 568 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 569 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 570 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 571 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 572 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 573 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 574 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 575 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 576 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 577 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 578 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 579 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 580 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 581 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 582 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 583 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 584 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 585 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 586 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 587 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 588 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 589 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 590 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 591 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 592 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 593 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 594 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 595 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 596 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 597 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 598 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 599 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 600 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 601 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 602 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 603 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 604 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 605 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 606 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 607 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 608 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 609 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 610 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 611 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 612 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 613 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 614 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 615 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 616 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 617 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 618 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 619 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 620 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 621 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 622 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 623 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 624 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 625 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 626 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 627 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 628 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 629 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 630 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 631 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 632 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 633 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 634 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 635 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 636 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 637 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 638 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 639 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 640 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 641 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 642 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 643 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 644 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 645 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 646 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 647 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 648 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 649 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 650 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 651 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 652 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 653 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 654 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 655 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 656 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 657 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 658 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 659 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 660 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 661 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 662 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 663 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 664 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 665 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 666 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 667 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 668 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 669 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 670 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 671 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 672 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 673 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 674 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 675 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 676 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 677 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 678 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 679 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 680 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 681 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 682 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 683 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 684 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 685 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 686 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 687 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 688 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 689 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 690 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 691 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 692 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 693 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 694 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 695 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 696 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 697 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 698 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 699 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 700 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 701 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 702 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 703 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 704 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 705 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 706 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 707 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 708 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 709 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 710 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 711 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 712 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 713 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 714 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 715 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 716 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 717 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 718 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 719 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 720 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 721 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 722 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 723 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 724 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 725 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 726 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 727 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 728 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 729 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 730 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 731 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 732 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 733 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 734 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 735 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 736 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 737 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 738 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 739 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 740 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 741 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 742 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 743 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 744 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 745 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 746 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 747 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 748 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 749 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 750 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 751 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 752 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 753 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 754 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 755 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 756 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 757 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 758 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 759 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 760 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 761 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 762 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 763 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 764 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 765 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 766 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 767 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 768 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 769 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 770 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 771 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 772 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 773 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 774 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 775 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 776 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 777 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 778 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 779 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 780 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 781 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 782 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 783 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 784 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 785 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 786 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 787 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 788 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 789 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 790 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 791 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 792 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 793 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 794 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 795 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 796 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 797 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 798 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 799 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 800 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 801 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 802 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 803 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 804 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 805 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 806 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 807 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 808 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 809 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 810 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 811 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 812 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 813 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 814 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 815 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 816 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 817 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 818 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 819 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 820 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 821 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 822 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 823 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 824 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 825 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 826 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 827 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 828 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 829 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 830 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 831 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 832 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 833 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 834 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 835 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 836 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 837 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 838 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 839 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 840 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 841 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 842 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 843 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 844 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 845 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 846 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 847 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 848 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 849 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 850 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 851 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 852 |  반복 1 / 2 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 853 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 854 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 855 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 856 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 857 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 858 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 859 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 860 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 861 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 862 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 863 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 864 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 865 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 866 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 867 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 868 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 869 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 870 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 871 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 872 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 873 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 874 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 875 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 876 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 877 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 878 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 879 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 880 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 881 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 882 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 883 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 884 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 885 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 886 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 887 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 888 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 889 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 890 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 891 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 892 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 893 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 894 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 895 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 896 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 897 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 898 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 899 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 900 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 901 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 902 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 903 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 904 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 905 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 906 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 907 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 908 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 909 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 910 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 911 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 912 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 913 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 914 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 915 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 916 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 917 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 918 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 919 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 920 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 921 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 922 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 923 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 924 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 925 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 926 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 927 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 928 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 929 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 930 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 931 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 932 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 933 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 934 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 935 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 936 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 937 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 938 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 939 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 940 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 941 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 942 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 943 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 944 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 945 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 946 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 947 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 948 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 949 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 950 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 951 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 952 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 953 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 954 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 955 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 956 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 957 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 958 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
            "| 에폭 959 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 960 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 961 |  반복 1 / 2 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 962 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
            "| 에폭 963 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 964 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 965 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 966 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 967 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 968 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 969 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 970 |  반복 1 / 2 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 971 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 972 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 973 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 974 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 975 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 976 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 977 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 978 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 979 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 980 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 981 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 982 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 983 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 984 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 985 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 986 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 987 |  반복 1 / 2 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 988 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 989 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 990 |  반복 1 / 2 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 991 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 992 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 993 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 994 |  반복 1 / 2 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 995 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 996 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 997 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 998 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 999 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 1000 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vecs = model.word_vecs ; word_vecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elST91BR5DwT",
        "outputId": "10e7e870-396e-42a9-e686-fdf9f1b0b570"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.74539   ,  0.97889787, -0.94558877,  0.9217437 ,  0.9969784 ],\n",
              "       [ 0.4153673 , -1.1579971 ,  1.2081553 , -1.18737   , -1.1780249 ],\n",
              "       [ 0.19706808,  1.040546  , -0.9848199 ,  1.0780019 ,  1.0026276 ],\n",
              "       [ 1.7932583 , -0.8421571 ,  0.92804563, -0.84528714, -0.85019445],\n",
              "       [ 0.19005889,  1.029755  , -0.98065865,  1.072977  ,  0.9650643 ],\n",
              "       [-1.7530444 ,  0.9895961 , -0.948117  ,  0.9193398 ,  0.98405886],\n",
              "       [-1.7064844 , -1.1514366 ,  1.1755863 , -1.182577  , -1.1317255 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word_id, word in id_to_word.items(): \n",
        "  print(word, word_vecs[word_id])\n",
        "# 단어를 밀집벡터로 나타낼수있게됨\n",
        "# 밀집벡터가 단어의 분산표현임\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDXTEBzc5oMj",
        "outputId": "ec9efecb-5b1e-4f63-bde4-82565c4e46f4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you [-1.74539     0.97889787 -0.94558877  0.9217437   0.9969784 ]\n",
            "say [ 0.4153673 -1.1579971  1.2081553 -1.18737   -1.1780249]\n",
            "goodbye [ 0.19706808  1.040546   -0.9848199   1.0780019   1.0026276 ]\n",
            "and [ 1.7932583  -0.8421571   0.92804563 -0.84528714 -0.85019445]\n",
            "i [ 0.19005889  1.029755   -0.98065865  1.072977    0.9650643 ]\n",
            "hello [-1.7530444   0.9895961  -0.948117    0.9193398   0.98405886]\n",
            ". [-1.7064844 -1.1514366  1.1755863 -1.182577  -1.1317255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec보충\n",
        "# skip gram 모델\n",
        "# 중앙의 단어로부터 주변의 여러단어를 추측함\n",
        "# 입력층 하나, 출력층은 맥락의 수만큼 존재함\n",
        "# 각 출력층에서는 softmax with loss계층을 이용해 개별적으로 손실을 구하고, 개별손신들을 모두 더한값을 최종손실로 사용\n",
        "# skip gram vs CBOW : skip gram사용 / 이유: 정밀도 면에서 skip gram이 우세함\n",
        "# 학습속도면에서는 CBOW가 더 빠름 / SKIP GRAM은 맥락의 수만큼 손실을 구해야해서 계산비용이 그만큼 커짐\n"
      ],
      "metadata": {
        "id": "kR19_QoI5-B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WORD2VEC이후에 통계기반기법과 추론기반기법을 융합한 GloVe가 등장\n",
        "# GloVe는 말뭉치 전체의 통계정보를 손실함수에 도입해 미니배치학습을 하는것임\n"
      ],
      "metadata": {
        "id": "3vZsJ2S_5x0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch4. word2vec 속도개선 "
      ],
      "metadata": {
        "id": "XtrjTocMBNUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cSNXAeJEBRYk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}